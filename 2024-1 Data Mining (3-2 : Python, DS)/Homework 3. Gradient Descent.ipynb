{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-IQrrZJc15_X"
      },
      "source": [
        "# Homework 3. Gradient Descent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7H80nVZv15_a"
      },
      "source": [
        "***Double Click here to edit this cell***\n",
        "\n",
        "- Name: 김대현\n",
        "- Student ID: 202000449\n",
        "- Submission date: 24.05.03"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xcuuKAAN15_b"
      },
      "source": [
        "# You must run this homework code on Google Colab\n",
        "\n",
        "- DON'T run on Google Colab Pro\n",
        "- DON'T use GPU or TPU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u-H_3fRo15_b"
      },
      "source": [
        "### You must run the following two cells to make sure you are running on Google Colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cKY6c7Ny15_c",
        "outputId": "46cf74f4-c32f-4df3-b095-7c67c8acc6b5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "processor\t: 0\n",
            "vendor_id\t: GenuineIntel\n",
            "cpu family\t: 6\n",
            "model\t\t: 79\n",
            "model name\t: Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "stepping\t: 0\n",
            "microcode\t: 0xffffffff\n",
            "cpu MHz\t\t: 2200.192\n",
            "cache size\t: 56320 KB\n",
            "physical id\t: 0\n",
            "siblings\t: 2\n",
            "core id\t\t: 0\n",
            "cpu cores\t: 1\n",
            "apicid\t\t: 0\n",
            "initial apicid\t: 0\n",
            "fpu\t\t: yes\n",
            "fpu_exception\t: yes\n",
            "cpuid level\t: 13\n",
            "wp\t\t: yes\n",
            "flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm rdseed adx smap xsaveopt arat md_clear arch_capabilities\n",
            "bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs taa mmio_stale_data retbleed\n",
            "bogomips\t: 4400.38\n",
            "clflush size\t: 64\n",
            "cache_alignment\t: 64\n",
            "address sizes\t: 46 bits physical, 48 bits virtual\n",
            "power management:\n",
            "\n",
            "processor\t: 1\n",
            "vendor_id\t: GenuineIntel\n",
            "cpu family\t: 6\n",
            "model\t\t: 79\n",
            "model name\t: Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "stepping\t: 0\n",
            "microcode\t: 0xffffffff\n",
            "cpu MHz\t\t: 2200.192\n",
            "cache size\t: 56320 KB\n",
            "physical id\t: 0\n",
            "siblings\t: 2\n",
            "core id\t\t: 0\n",
            "cpu cores\t: 1\n",
            "apicid\t\t: 1\n",
            "initial apicid\t: 1\n",
            "fpu\t\t: yes\n",
            "fpu_exception\t: yes\n",
            "cpuid level\t: 13\n",
            "wp\t\t: yes\n",
            "flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm rdseed adx smap xsaveopt arat md_clear arch_capabilities\n",
            "bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs taa mmio_stale_data retbleed\n",
            "bogomips\t: 4400.38\n",
            "clflush size\t: 64\n",
            "cache_alignment\t: 64\n",
            "address sizes\t: 46 bits physical, 48 bits virtual\n",
            "power management:\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!cat /proc/cpuinfo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y1QR-Owo15_d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e636cddb-8cba-4d56-8ff7-71f1ac08e885"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MemTotal:       13290480 kB\n",
            "MemFree:         8829956 kB\n",
            "MemAvailable:   12474596 kB\n",
            "Buffers:          333168 kB\n",
            "Cached:          3497836 kB\n",
            "SwapCached:            0 kB\n",
            "Active:           603716 kB\n",
            "Inactive:        3635328 kB\n",
            "Active(anon):       1216 kB\n",
            "Inactive(anon):   408600 kB\n",
            "Active(file):     602500 kB\n",
            "Inactive(file):  3226728 kB\n",
            "Unevictable:           4 kB\n",
            "Mlocked:               4 kB\n",
            "SwapTotal:             0 kB\n",
            "SwapFree:              0 kB\n",
            "Dirty:               680 kB\n",
            "Writeback:             0 kB\n",
            "AnonPages:        408056 kB\n",
            "Mapped:           266508 kB\n",
            "Shmem:              1772 kB\n",
            "KReclaimable:     112700 kB\n",
            "Slab:             148560 kB\n",
            "SReclaimable:     112700 kB\n",
            "SUnreclaim:        35860 kB\n",
            "KernelStack:        4496 kB\n",
            "PageTables:         5952 kB\n",
            "SecPageTables:         0 kB\n",
            "NFS_Unstable:          0 kB\n",
            "Bounce:                0 kB\n",
            "WritebackTmp:          0 kB\n",
            "CommitLimit:     6645240 kB\n",
            "Committed_AS:    2074012 kB\n",
            "VmallocTotal:   34359738367 kB\n",
            "VmallocUsed:       10736 kB\n",
            "VmallocChunk:          0 kB\n",
            "Percpu:             1088 kB\n",
            "HardwareCorrupted:     0 kB\n",
            "AnonHugePages:      4096 kB\n",
            "ShmemHugePages:        0 kB\n",
            "ShmemPmdMapped:        0 kB\n",
            "FileHugePages:         0 kB\n",
            "FilePmdMapped:         0 kB\n",
            "CmaTotal:              0 kB\n",
            "CmaFree:               0 kB\n",
            "Unaccepted:            0 kB\n",
            "HugePages_Total:       0\n",
            "HugePages_Free:        0\n",
            "HugePages_Rsvd:        0\n",
            "HugePages_Surp:        0\n",
            "Hugepagesize:       2048 kB\n",
            "Hugetlb:               0 kB\n",
            "DirectMap4k:       68408 kB\n",
            "DirectMap2M:     4122624 kB\n",
            "DirectMap1G:    11534336 kB\n"
          ]
        }
      ],
      "source": [
        "!cat /proc/meminfo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7EkUtm1O15_d"
      },
      "source": [
        "## Remark: gradient_descent.py, linear_algebra.py must be in the folder having this notebook file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LdFtZkI215_e"
      },
      "outputs": [],
      "source": [
        "# run this cell\n",
        "from gradient_descent import *\n",
        "from linear_algebra import *"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3a5-03xM15_e"
      },
      "source": [
        "## Problem 1 (5 pts) : 5\n",
        "\n",
        "- The following function has a minimum at $(2, 3)$\n",
        "$$\n",
        "f(x_1, x_2) = (x_1 - 2)^2 + (x_2 - 3)^2\n",
        "$$\n",
        "\n",
        "- We want to compute the minimum of $f$ using the gradient descent algorithm\n",
        "- Define a function (```f```) and gradient of function (```f_gradient```)\n",
        "- **Do NOT use numpy functions to define f and f_gradient**\n",
        "- **USE functions in linear_algebra.py**\n",
        "### <span style=\"color:red\">**You write two functions. Each function must have ONE line of code in function body; Otherwise, you get zero point (0점)**</span>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 문제 1 (5 점)\n",
        "\n",
        "- 다음 함수는 $(2, 3)$에서 최소값을 가집니다.\n",
        "$$\n",
        "f(x_1, x_2) = (x_1 - 2)^2 + (x_2 - 3)^2\n",
        "$$\n",
        "\n",
        "- 그래디언트 강하 알고리즘을 사용하여 $f$의 최소값을 계산하고자 합니다.\n",
        "- 함수(```f```)와 함수의 그래디언트(```f_gradient```)를 정의하세요.\n",
        "- **numpy 함수를 사용하지 마세요.**\n",
        "- **linear_algebra.py의 함수를 사용하세요.**\n",
        "### <span style=\"color:red\">**두 개의 함수를 작성하세요. 각 함수는 함수 본문에 한 줄의 코드만 있어야 합니다. 그렇지 않으면 점수가 0점입니다.**</span>"
      ],
      "metadata": {
        "id": "8WOvpY60SAgt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UrlvzYrT15_f"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE MUST BE HERE\n",
        "def f(v):\n",
        "  return sum_of_squares(vector_subtract(v, [2, 3])) #v와 [2, 3] 사이의 제곱합 반환\n",
        "\n",
        "def f_gradient(v):\n",
        "  return scalar_multiply(2, vector_subtract(v, [2, 3])) #v와 [2, 3] 사이의 벡터를 구하고 2를 곱해서 반환"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KqOfmKfP15_f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23529633-c1bb-4408-bfb7-b44b7ad53f14"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 1.43 ms, sys: 0 ns, total: 1.43 ms\n",
            "Wall time: 1.44 ms\n",
            "solution is [1.997524119921429, 2.996286179882144]\n",
            "++++++++++ Problem 1 check passed ++++++++++\n"
          ]
        }
      ],
      "source": [
        "# DO NOT EDIT THIS CELL\n",
        "# RUN THIS CELL\n",
        "\n",
        "init_x = [0.,0.]\n",
        "%time solution = minimize_batch(f, f_gradient, init_x, tolerance=0.00001)\n",
        "\n",
        "### correctness check\n",
        "print('solution is {}'.format(solution))\n",
        "EPSILON = 0.01\n",
        "cond1 = math.fabs(solution[0] - 2.0) <= EPSILON\n",
        "cond2 = math.fabs(solution[1] - 3.0) <= EPSILON\n",
        "assert  all([cond1, cond2]), '-'*10 + ' Problem 1 check failed ' + '-'*10\n",
        "print('+'*10 + ' Problem 1 check passed ' + '+'*10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TyCFgq3w15_f"
      },
      "source": [
        "## Problem 2 (10 pts) : 10\n",
        "\n",
        "- The centroid of a finite set of $\\displaystyle {k}$ points $\\displaystyle \\mathbf {x} _{1},\\mathbf {x} _{2},\\ldots ,\\mathbf {x} _{k}$ in $\\displaystyle \\mathbb {R} ^{n}$ is\n",
        "$$\n",
        "\\mathbf {C} ={\\frac {\\mathbf {x} _{1}+\\mathbf {x} _{2}+\\cdots +\\mathbf {x} _{k}}{k}}\n",
        "$$\n",
        "\n",
        "- We want to compute a centroid by **minimizing the mean of squared Euclidean distances between itself and each point in the set**\n",
        "$$\n",
        "x_{\\text{centroid}} = \\text{argmin}_{\\text{c}} {\\frac{\\sum_{i=1}^{n}d({\\text{c}}, x_i)^2}{n}}\n",
        "$$\n",
        "- Define a function (```sq_dist```) and gradient of function (```sq_dist_gradient```)\n",
        "- **Do NOT use numpy functions to define sq_dist and sq_dist_gradient**\n",
        "- **USE functions in linear_algebra.py**\n",
        "### <span style=\"color:red\">**You write two functions. Each function must have ONE line of code in function body; Otherwise, you get zero point (0점)**</span>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 문제 2 (10 점)\n",
        "\n",
        "- $\\displaystyle \\mathbb {R} ^{n}$의 유한한 $\\displaystyle {k}$ 개의 점 $\\displaystyle \\mathbf {x} _{1},\\mathbf {x} _{2},\\ldots ,\\mathbf {x} _{k}$의 중심은 다음과 같습니다.\n",
        "$$\n",
        "\\mathbf {C} ={\\frac {\\mathbf {x} _{1}+\\mathbf {x} _{2}+\\cdots +\\mathbf {x} _{k}}{k}}\n",
        "$$\n",
        "\n",
        "- **자신과 집합 내의 각 점 사이의 평균 제곱 유클리드 거리를 최소화하여 중심을 계산하고자 합니다**\n",
        "$$\n",
        "x_{\\text{centroid}} = \\text{argmin}_{\\text{c}} {\\frac{\\sum_{i=1}^{n}d({\\text{c}}, x_i)^2}{n}}\n",
        "$$\n",
        "- 함수(```sq_dist```)와 함수의 그래디언트(```sq_dist_gradient```)를 정의하세요.\n",
        "- **numpy 함수를 사용하지 마세요.**\n",
        "- **linear_algebra.py의 함수를 사용하세요.**\n",
        "### <span style=\"color:red\">**두 개의 함수를 작성하세요. 각 함수는 함수 본문에 한 줄의 코드만 있어야 합니다. 그렇지 않으면 점수가 0점입니다.**</span>"
      ],
      "metadata": {
        "id": "tZMUqQhKSFoL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K_MOsJbC15_g"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE MUST BE HERE\n",
        "def sq_dist(c,X):\n",
        "  return squared_distance(c,vector_mean(X)) # 중심 c & 점의 집합 X의 평균사이 제곱 거리 반환\n",
        "\n",
        "def sq_dist_gradient(c,X):\n",
        "  return scalar_multiply(2,vector_subtract(c,vector_mean(X)))  # 중심 c & 점의 집합 X의 평균사이 백터 구하고 x 2 하여 반환"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4CGydYeI15_g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0eb6cd0-22d1-452f-cd9e-dfa06832cfc4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 75.2 ms, sys: 0 ns, total: 75.2 ms\n",
            "Wall time: 79.8 ms\n",
            "solution is [99.99885075808741, 700.1414374609792]\n",
            "++++++++++ Problem 2 check passed ++++++++++\n"
          ]
        }
      ],
      "source": [
        "# DO NOT EDIT THIS CELL\n",
        "# RUN THIS CELL\n",
        "\n",
        "from functools import partial\n",
        "import numpy as np\n",
        "\n",
        "np.random.seed(0)\n",
        "c = np.array([100,700])\n",
        "X = c + np.random.randn(100,2)\n",
        "\n",
        "f = partial(sq_dist, X=X)\n",
        "gradient_f = partial(sq_dist_gradient, X=X)\n",
        "init_x = np.array([0.,0.])\n",
        "%time solution = minimize_batch(f, gradient_f, init_x)\n",
        "\n",
        "### correctness check\n",
        "print('solution is {}'.format(solution))\n",
        "EPSILON = 1\n",
        "cond1 = math.fabs(solution[0] - 100.0) <= EPSILON\n",
        "cond2 = math.fabs(solution[1] - 700.0) <= EPSILON\n",
        "assert  all([cond1, cond2]), '-'*10 + ' Problem 2 check failed ' + '-'*10\n",
        "print('+'*10 + ' Problem 2 check passed ' + '+'*10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-kMOVlDu15_g",
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25f4eabe-7bbf-46ac-affb-6584bd1bcbe2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: type: gradient_descent.py: not found\n"
          ]
        }
      ],
      "source": [
        "!type gradient_descent.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h9DK8thH15_h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11a50513-e1c4-4030-e620-f11038419716"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 1min 1s, sys: 166 ms, total: 1min 1s\n",
            "Wall time: 1min 6s\n",
            "solution is [99.99988468682899, 700.0052527466783]\n",
            "++++++++++ Problem 2 check passed ++++++++++\n"
          ]
        }
      ],
      "source": [
        "# DO NOT EDIT THIS CELL\n",
        "# RUN THIS CELL\n",
        "\n",
        "from functools import partial\n",
        "import numpy as np\n",
        "\n",
        "np.random.seed(0)\n",
        "c = np.array([100,700])\n",
        "X = c + np.random.randn(100000,2)     # 100 thousands\n",
        "\n",
        "f = partial(sq_dist, X=X)\n",
        "gradient_f = partial(sq_dist_gradient, X=X)\n",
        "init_x = np.array([0.,0.])\n",
        "%time solution = minimize_batch(f, gradient_f, init_x)\n",
        "\n",
        "### correctness check\n",
        "print('solution is {}'.format(solution))\n",
        "EPSILON = 1\n",
        "cond1 = math.fabs(solution[0] - 100.0) <= EPSILON\n",
        "cond2 = math.fabs(solution[1] - 700.0) <= EPSILON\n",
        "assert  all([cond1, cond2]), '+'*10 + ' Problem 2 check failed ' + '-'*10\n",
        "print('+'*10 + ' Problem 2 check passed ' + '+'*10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bQk9Hgf-15_h"
      },
      "source": [
        "**Time taken in my computer**:\n",
        "```\n",
        "Wall time: 2min 22s\n",
        "solution is [99.99988468682913, 700.0052527466843]\n",
        "++++++++++ Problem 2 check passed ++++++++++\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C5rgChZH15_h"
      },
      "source": [
        "## Problem 3 (10 pts) : 10\n",
        "\n",
        "- Continued from Problem 2\n",
        "- We want to compute a centroid\n",
        "- Define a function (```sq_dist_numpy```) and gradient of function (```sq_dist_gradient_numpy```)\n",
        "- **Use numpy functions to define sq_dist and sq_dist_gradient**\n",
        "- **Do NOT use functions in linear_algebra.py**\n",
        "### <span style=\"color:red\">**You write two functions. Each function must have ONE line of code in function body; Otherwise, you get zero point (0점)**</span>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 문제 3 (10 점)\n",
        "\n",
        "- 문제 2에서 계속\n",
        "- 중심을 계산하고자 합니다\n",
        "- 함수(```sq_dist_numpy```)와 함수의 그래디언트(```sq_dist_gradient_numpy```)를 정의하세요.\n",
        "- **numpy 함수를 사용하여 sq_dist 및 sq_dist_gradient를 정의하세요.**\n",
        "- **linear_algebra.py의 함수를 사용하지 마세요.**\n",
        "### <span style=\"color:red\">**두 개의 함수를 작성하세요. 각 함수는 함수 본문에 한 줄의 코드만 있어야 합니다. 그렇지 않으면 점수가 0점입니다.**</span>"
      ],
      "metadata": {
        "id": "eHfzpmcMSLjs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vpsoDiti15_h"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE MUST BE HERE\n",
        "def sq_dist_numpy(c,X):\n",
        "    return np.mean(np.sum((c - X)**2, axis=1)) # 중심 c & 점의 집합 X의 제곱거리의 평균 반환\n",
        "\n",
        "def sq_dist_gradient_numpy(c,X):\n",
        "  return 2 * np.mean(c-X, axis=0) # 중심 c & 점의 집합 X의 벡터평균을 구하고 x 2 하여 반환"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8yImQY2m15_h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18f39ea9-ed75-4c18-84b1-4691a4c67a78"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 1.74 s, sys: 3.04 ms, total: 1.75 s\n",
            "Wall time: 1.75 s\n",
            "[99.99988468682913, 700.0052527466843]\n",
            "++++++++++ Problem 3 check passed ++++++++++\n"
          ]
        }
      ],
      "source": [
        "# DO NOT EDIT THIS CELL\n",
        "# RUN THIS CELL\n",
        "\n",
        "from functools import partial\n",
        "\n",
        "np.random.seed(0)\n",
        "c = np.array([100,700])\n",
        "X = c + np.random.randn(100000,2)\n",
        "\n",
        "f = partial(sq_dist_numpy, X=X)\n",
        "gradient_f = partial(sq_dist_gradient_numpy, X=X)\n",
        "init_x = np.array([0.,0.])\n",
        "%time solution = minimize_batch(f, gradient_f, init_x)\n",
        "\n",
        "### correctness check\n",
        "print(solution)\n",
        "EPSILON = 1\n",
        "cond1 = math.fabs(solution[0] - 100.0) <= EPSILON\n",
        "cond2 = math.fabs(solution[1] - 700.0) <= EPSILON\n",
        "assert  all([cond1, cond2]), '-'*10 + ' Problem 3 check failed ' + '-'*10\n",
        "print('+'*10 + ' Problem 3 check passed ' + '+'*10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KBrEXJnj15_h"
      },
      "source": [
        "**Time taken in my computer**:\n",
        "```\n",
        "Wall time: 1.49 s\n",
        "[99.99988468682913, 700.0052527466843]\n",
        "++++++++++ Problem 3 check passed ++++++++++\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mnhu5bZG15_h"
      },
      "source": [
        "## Problem 4 (10 pts) : 10\n",
        "\n",
        "- We want to compute a centroid using Manhattan distance\n",
        "- Define a function (```abs_diff_numpy```) and gradient of function (```abs_diff_gradient_numpy```)\n",
        "- Use numpy functions to define abs_diff_numpy and abs_diff_gradient_numpy\n",
        "- Do NOT use functions in linear_algebra.py\n",
        "### <span style=\"color:red\">**Each function must have ONE line of code; Otherwise, you get zero point (0점)**</span>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 문제 4 (10 점)\n",
        "\n",
        "- 맨하탄 거리를 사용하여 중심을 계산하고자 합니다\n",
        "- 함수(```abs_diff_numpy```)와 함수의 그래디언트(```abs_diff_gradient_numpy```)를 정의하세요.\n",
        "- numpy 함수를 사용하여 abs_diff_numpy 및 abs_diff_gradient_numpy를 정의하세요.\n",
        "- linear_algebra.py의 함수를 사용하지 마세요.\n",
        "### <span style=\"color:red\">**각 함수는 한 줄의 코드만 있어야 합니다. 그렇지 않으면 점수가 0점입니다.**</span>"
      ],
      "metadata": {
        "id": "6R7LLVtLSPtj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XnsxARi715_i"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE MUST BE HERE\n",
        "def abs_diff_numpy(c, X):\n",
        "  return np.mean(np.sum(np.fabs(c - X), axis=1), axis=0) # 중심 c, 점들의 집합 X 사이의 절대차이 평균 반환\n",
        "\n",
        "def abs_diff_gradient_numpy(c, X):\n",
        "  return (c - np.mean(X, axis=0)) / np.mean(np.fabs(c - X), axis=0) # 중심 c, 점들의 집합 X 사이의 절대차이 평균을 계산하여 반환"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KJbmUrZ-15_i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c9fa34b-4d27-4fbf-f40c-637ea949c247"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 3.38 ms, sys: 0 ns, total: 3.38 ms\n",
            "Wall time: 3.84 ms\n",
            "[99.230295466202, 99.28466636629629]\n",
            "++++++++++ Problem 4 check passed ++++++++++\n"
          ]
        }
      ],
      "source": [
        "# DO NOT EDIT THIS CELL\n",
        "# RUN THIS CELL\n",
        "\n",
        "np.random.seed(0)\n",
        "# c = np.array([100,700])\n",
        "# X = c + np.random.randn(100,2)\n",
        "c1 = np.array([100,100])\n",
        "X1 = c1 + np.random.randn(100,2)\n",
        "c2 = np.array([100,0])\n",
        "X2 = c2 + np.random.randn(100,2)\n",
        "c3 = np.array([0,100])\n",
        "X3 = c3 + np.random.randn(100,2)\n",
        "X  = np.vstack((X1, X2, X3))\n",
        "\n",
        "f = partial(abs_diff_numpy, X=X)\n",
        "gradient_f = partial(abs_diff_gradient_numpy, X=X)\n",
        "init_x = np.array([0.,0.])\n",
        "%time solution = minimize_batch(f, gradient_f, init_x)\n",
        "\n",
        "### correctness check\n",
        "print(solution)\n",
        "EPSILON = 1\n",
        "cond1 = math.fabs(solution[0] - 100.0) <= EPSILON\n",
        "cond2 = math.fabs(solution[1] - 100.0) <= EPSILON\n",
        "assert  all([cond1, cond2]), '-'*10 + ' Problem 4 check failed ' + '-'*10\n",
        "print('+'*10 + ' Problem 4 check passed ' + '+'*10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mORMVqe_15_i"
      },
      "source": [
        "## Problem 5 (15 pts) : 13\n",
        "\n",
        "- We want to rewrite ```minimize_batch```.\n",
        "- Do NOT use ```step``` function; provide numpy style code using broadcasting\n",
        "    - Do NOT use ```[step(theta, gradient, -step_size) for step_size in step_sizes]```\n",
        "- Modify ```minimize_batch``` to take ```step_sizes``` as an argument\n",
        "- Modify ```minimize_batch``` to take maximum number of epochs as an argument\n",
        "    - epoch is the number of ```while``` loop iterations in the following code.\n",
        "- Modify ```minimize_batch``` to return ```epoch``` together with ```theta```\n",
        "- Modify ```minimize_batch``` to return ```None``` as solution if it does not converge within max_steps\n",
        "- **Use numpy functions to define sq_dist_numpy_1 and sq_dist_gradient_numpy_1**\n",
        "- **Do NOT use functions in linear_algebra.py**\n",
        "- If all done, now you have an enhanced numpy version of minimize_batch"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 문제 5 (15 점)\n",
        "\n",
        "- ```minimize_batch```를 다시 작성하고자 합니다.\n",
        "- ```step``` 함수를 사용하지 마세요. 브로드캐스팅을 사용하여 numpy 스타일의 코드를 제공하세요.\n",
        "    - ```[step(theta, gradient, -step_size) for step_size in step_sizes]```를 사용하지 마세요.\n",
        "- ```minimize_batch```를 수정하여 ```step_sizes```를 인수로 받도록 하세요.\n",
        "- ```minimize_batch```를 수정하여 최대 에포크 수를 인수로 받도록 하세요.\n",
        "    - 에포크는 다음 코드의 ```while``` 루프 반복 횟수입니다.\n",
        "- ```minimize_batch```를 수정하여 ```epoch```와 함께 ```theta```를 반환하도록 하세요.\n",
        "- ```minimize_batch```를 수정하여 최대 단계 수 내에서 수렴하지 않으면 솔루션으로 ```None```을 반환하도록 하세요.\n",
        "- sq_dist_numpy_1 및 sq_dist_gradient_numpy_1을 정의하기 위해 numpy 함수를 사용하세요.\n",
        "- linear_algebra.py의 함수를 사용하지 마세요.\n",
        "- 모두 완료되면 이제 향상된 numpy 버전의 minimize_batch가 있습니다."
      ],
      "metadata": {
        "id": "RruRUKeJSXAl"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qdn9TPT-15_i"
      },
      "source": [
        "The following is ```minimize_batch``` in our textbook\n",
        "```python\n",
        "def minimize_batch(target_fn, gradient_fn, theta_0, tolerance=0.000001):\n",
        "    \"\"\"use gradient descent to find theta that minimizes target function\"\"\"\n",
        "\n",
        "    step_sizes = [100, 10, 1, 0.1, 0.01, 0.001, 0.0001, 0.00001]\n",
        "\n",
        "    theta = theta_0                           # set theta to initial value\n",
        "    target_fn = safe(target_fn)               # safe version of target_fn\n",
        "    value = target_fn(theta)                  # value we're minimizing\n",
        "\n",
        "    while True:\n",
        "        gradient = gradient_fn(theta)\n",
        "        next_thetas = [step(theta, gradient, -step_size)\n",
        "                       for step_size in step_sizes]\n",
        "\n",
        "        # choose the one that minimizes the error function\n",
        "        next_theta = min(next_thetas, key=target_fn)\n",
        "        next_value = target_fn(next_theta)\n",
        "\n",
        "        # stop if we're \"converging\"\n",
        "        if abs(value - next_value) < tolerance:\n",
        "            return theta\n",
        "        else:\n",
        "            theta, value = next_theta, next_value\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bh04X1Wz15_i"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE MUST BE HERE\n",
        "\n",
        "def minimize_batch_enhanced(target_fn, gradient_fn, theta_0, step_sizes, max_steps=10000, tolerance=0.000001):\n",
        "\n",
        "  theta = np.array(theta_0) # 초기 파라미터 값 설정 (세타)\n",
        "  value = target_fn(theta) # theta에 대한 목표 함수 target_fn의 값을 계산하는 부분\n",
        "  epoch = 0 # 학습 횟수\n",
        "\n",
        "  for _ in range(max_steps):\n",
        "    gradient = gradient_fn(theta) # 새타의 gradient 계산\n",
        "    next_thetas = theta - step_sizes[:, np.newaxis] * gradient # 다음 파라미터 후보들 계산\n",
        "    next_values = np.apply_along_axis(target_fn, 1, next_thetas) # 후보들에 대한 목표함수 값 계산\n",
        "    min_index = np.argmin(next_values) # 후보들중 목표함수 값이 가장 작은 인덱스 찾기\n",
        "    next_theta, next_value = next_thetas[min_index], next_values[min_index] # 목표함수 값이 가장 작은 후보를 다음 파라미터로 지정\n",
        "\n",
        "    if abs(value - next_value) < tolerance: # 현재,다음 파라미터 사이 목표함수 값 차이가 허용 오차보다 작으면 수렴으로 판단\n",
        "      return theta,epoch\n",
        "    else:\n",
        "      theta, value = next_theta, next_value\n",
        "    epoch+=1\n",
        "\n",
        "  return None,epoch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nmmvEgV415_i"
      },
      "source": [
        "### <span style=\"color:red\">**Each function must have ONE line of code; Otherwise, you get zero point (0점)**</span>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IkNMEeen15_i"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE MUST BE HERE\n",
        "def sq_dist_numpy_1(c,X):\n",
        "  return np.mean(np.sum((X-c)**2,axis=1)) # X에서 c를 빼고 제곱하여 각차원 별 제곱 거리를 구하고, 모든 데이터를 합하고 평균을 구함\n",
        "\n",
        "def sq_dist_gradient_numpy_1(c,X):\n",
        "  return 2*np.mean(c-X,axis=0) # c에서 X를 뺀 값의 평균 2배 -> 평균 제곱 거리의 그래디언트"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8CxRA7v215_i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97d67306-296e-4cfc-84d3-cfb4a3fce161"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Solution [ 99.78192923 699.8960156 ] found at epoch 587\n",
            "Problem 5 check passed\n"
          ]
        }
      ],
      "source": [
        "# DO NOT EDIT THIS CELL\n",
        "# RUN THIS CELL\n",
        "\n",
        "from functools import partial\n",
        "import numpy as np\n",
        "\n",
        "np.random.seed(0)\n",
        "c = np.array([100,700])\n",
        "X = c + 10*np.random.randn(1000,2)\n",
        "\n",
        "f = partial(sq_dist_numpy_1, X=X)\n",
        "gradient_f = partial(sq_dist_gradient_numpy_1, X=X)\n",
        "init_x = np.array([0.,0.])\n",
        "step_sizes = np.array([0.01])\n",
        "\n",
        "solution, epoch = minimize_batch_enhanced(f, gradient_f, init_x, step_sizes)\n",
        "### correctness check\n",
        "if solution is None:\n",
        "    print('Does not converge within epoch {}'.format(epoch))\n",
        "else:\n",
        "    print('Solution {} found at epoch {}'.format(solution, epoch))\n",
        "    EPSILON = 1\n",
        "    cond1 = math.fabs(solution[0] - 100.0) <= EPSILON\n",
        "    cond2 = math.fabs(solution[1] - 700.0) <= EPSILON\n",
        "    assert  all([cond1, cond2]), 'Problem 5 check failed'\n",
        "    print('Problem 5 check passed')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C44MMc7l15_i"
      },
      "source": [
        "Your solution should be like:\n",
        "```\n",
        "Solution [ 99.78192923 699.8960156 ] found at epoch 587\n",
        "Problem 5 check passed\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xBBHJPcL15_i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a34902f1-4742-4802-d998-97558b97bec2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "++++++++++ Test case [10] ++++++++++\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/core/_methods.py:118: RuntimeWarning: overflow encountered in reduce\n",
            "  ret = umr_sum(arr, axis, dtype, out, keepdims, where=where)\n",
            "<ipython-input-15-601bc089f485>:3: RuntimeWarning: overflow encountered in square\n",
            "  return np.mean(np.sum((X-c)**2,axis=1))\n",
            "<ipython-input-14-bf681e5598b4>:16: RuntimeWarning: invalid value encountered in scalar subtract\n",
            "  if abs(value - next_value) < tolerance:\n",
            "<ipython-input-14-bf681e5598b4>:11: RuntimeWarning: invalid value encountered in subtract\n",
            "  next_thetas = theta - step_sizes[:, np.newaxis] * gradient\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Does not converge within epoch 10000\n",
            "\n",
            "++++++++++ Test case [0.1] ++++++++++\n",
            "Solution [ 99.78244401 699.89962643] found at epoch 59\n",
            "Problem 5 check passed\n",
            "\n",
            "++++++++++ Test case [0.01] ++++++++++\n",
            "Solution [ 99.78192923 699.8960156 ] found at epoch 587\n",
            "Problem 5 check passed\n",
            "\n",
            "++++++++++ Test case [0.001] ++++++++++\n",
            "Solution [ 99.78040508 699.88532482] found at epoch 5349\n",
            "Problem 5 check passed\n",
            "\n",
            "++++++++++ Test case [0.0001] ++++++++++\n",
            "Does not converge within epoch 10000\n",
            "\n",
            "++++++++++ Test case [1.e-05] ++++++++++\n",
            "Does not converge within epoch 10000\n",
            "\n",
            "++++++++++ Test case [1.e-03 1.e-02 1.e-01 1.e+00 1.e+01 1.e+02 1.e+03] ++++++++++\n",
            "Solution [ 99.78244401 699.89962643] found at epoch 59\n",
            "Problem 5 check passed\n"
          ]
        }
      ],
      "source": [
        "# DO NOT EDIT THIS CELL\n",
        "# RUN THIS CELL\n",
        "\n",
        "from functools import partial\n",
        "import numpy as np\n",
        "\n",
        "np.random.seed(0)\n",
        "c = np.array([100,700])\n",
        "X = c + 10*np.random.randn(1000,2)\n",
        "\n",
        "f = partial(sq_dist_numpy_1, X=X)\n",
        "gradient_f = partial(sq_dist_gradient_numpy_1, X=X)\n",
        "init_x = np.array([0.,0.])\n",
        "step_sizes_set = [np.array([10]),\n",
        "                  np.array([0.1]),\n",
        "                  np.array([0.01]),\n",
        "                  np.array([0.001]),\n",
        "                  np.array([0.0001]),\n",
        "                  np.array([0.00001]),\n",
        "                  np.array(np.logspace(-3,3,7))\n",
        "                 ]\n",
        "\n",
        "for step_sizes in step_sizes_set:\n",
        "    print()\n",
        "    print('+'*10 + ' Test case {} '.format(step_sizes) + '+'*10)\n",
        "    solution, epoch = minimize_batch_enhanced(f, gradient_f, init_x, step_sizes)\n",
        "    ### correctness check\n",
        "    if solution is None:\n",
        "        print('Does not converge within epoch {}'.format(epoch))\n",
        "    else:\n",
        "        print('Solution {} found at epoch {}'.format(solution, epoch))\n",
        "        EPSILON = 1\n",
        "        cond1 = math.fabs(solution[0] - 100.0) <= EPSILON\n",
        "        cond2 = math.fabs(solution[1] - 700.0) <= EPSILON\n",
        "        assert  all([cond1, cond2]), 'Problem 5 check failed'\n",
        "        print('Problem 5 check passed')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q3nl5pR515_j"
      },
      "source": [
        "Your solution should be like:\n",
        "```\n",
        "++++++++++ Test case [10] ++++++++++\n",
        "...\n",
        "Numpy overflow warning\n",
        "...\n",
        "Does not converge within epoch 10000\n",
        "\n",
        "++++++++++ Test case [0.1] ++++++++++\n",
        "Solution [ 99.78244401 699.89962643] found at epoch 59\n",
        "Problem 5 check passed\n",
        "\n",
        "++++++++++ Test case [0.01] ++++++++++\n",
        "Solution [ 99.78192923 699.8960156 ] found at epoch 587\n",
        "Problem 5 check passed\n",
        "\n",
        "++++++++++ Test case [0.001] ++++++++++\n",
        "Solution [ 99.78040508 699.88532482] found at epoch 5349\n",
        "Problem 5 check passed\n",
        "\n",
        "++++++++++ Test case [0.0001] ++++++++++\n",
        "Does not converge within epoch 10000\n",
        "\n",
        "++++++++++ Test case [1.e-05] ++++++++++\n",
        "Does not converge within epoch 10000\n",
        "\n",
        "++++++++++ Test case [1.e-03 1.e-02 1.e-01 1.e+00 1.e+01 1.e+02 1.e+03] ++++++++++\n",
        "Solution [ 99.78244401 699.89962643] found at epoch 59\n",
        "Problem 5 check passed\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C3EW13c115_j"
      },
      "source": [
        "### Double click this cell to edit:\n",
        "\n",
        "What is your conclusion from experiments with the above several test cases?\n",
        "\n",
        "위의 여러 테스트 사례에 대한 실험에서 얻은 결론은 무엇입니까?\n",
        "\n",
        "```\n",
        "step_size가 0.1일 때 가장 적은 epoch 수로 최소값에 도달한 것으로 보임. 이는 step_size가 작을수록 gradient의 반대 방향으로 이동하는 거리가 짧아지고, 따라서 더 많은 epoch가 필요하게 되는 현상을 설명. 그러나 step_size가 너무 작으면 local minimum에 빠질 위험이 있음.또한, step_size가 10배 줄어들면 epoch 수도 대략 10배 정도 늘어나는 경향을 보임. 이를 통해, step_size가 0.0001과 0.00001인 경우 약 50000번과 500000번 반복하여 최소값에 수렴할 수 있을 것으로 예상. 그러나 실험에서는 epoch 수를 10000번으로 제한했기 때문에 이러한 step_size로는 최소값에 도달하지 못한 것으로 보임.\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g5JFHcWi15_j"
      },
      "source": [
        "## Ethics:\n",
        "If you cheat, you will get negatgive of the total points.\n",
        "If the homework total is 22 and you cheat, you get -22."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T0l9dyQk15_j"
      },
      "source": [
        "## What to submit\n",
        "\n",
        "- No late homeworks will be accepted (Google classroom will not accept late homework automatically\n",
        "- Your homework will be graded on the basis of correctness, performance, and programming skills"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "hide_input": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}